{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This cell has been split into multiple cells for better readability and a tutorial-like structure. Please refer to the new cells."
      ],
      "metadata": {
        "id": "FEE2kITXFBpt"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b999774a"
      },
      "source": [
        "## Complete CNN Image Classification Implementation\n",
        "\n",
        "This project demonstrates a complete Convolutional Neural Network (CNN) implementation for image classification, built using TensorFlow and OpenCV. It is structured into three main modules:\n",
        "\n",
        "1.  **`data_preprocess.py`**: Handles all data preparation steps, including renaming images, resizing them to a uniform dimension, and converting image metadata into a CSV format suitable for training.\n",
        "2.  **`train.py`**: Contains the CNN model definition and the training loop. It loads preprocessed data, builds a multi-layer CNN, and trains it to classify images.\n",
        "3.  **`predict.py`**: Implements the image recognition functionality. It loads the trained model and uses it to predict categories for new images or real-time video streams."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d6a4f54"
      },
      "source": [
        "### 1. Data Preprocessing Module (`data_preprocess.py`)\n",
        "\n",
        "This module is responsible for preparing the image dataset for model training. It includes functionalities to:\n",
        "\n",
        "-   **Rename images**: Standardize filenames to a `category-index.jpg` format.\n",
        "-   **Resize images**: Ensure all images have a consistent dimension (e.g., 200x200 pixels).\n",
        "-   **Generate CSV**: Create a CSV file that maps image paths to their respective labels, including one-hot encoded labels, which is essential for training the CNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7492e340"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class DataPreprocess:\n",
        "    def __init__(self, image_path=\"./picture/\", csv_path=\"./\"):\n",
        "        self.image_path = image_path\n",
        "        self.csv_path = csv_path\n",
        "\n",
        "    def rename(self):\n",
        "        \"\"\"\n",
        "        数据图片重命名\n",
        "        将数据集按照 类别-序号.jpg 格式重命名\n",
        "        \"\"\"\n",
        "        print(\"开始重命名图片...\")\n",
        "        listdir = os.listdir(self.image_path)\n",
        "        i = 0\n",
        "\n",
        "        while i < len(listdir):\n",
        "            category_path = os.path.join(self.image_path, listdir[i])\n",
        "            if not os.path.isdir(category_path):\n",
        "                i += 1\n",
        "                continue\n",
        "\n",
        "            images_list_dir = os.listdir(category_path)\n",
        "            j = 0\n",
        "\n",
        "            while j < len(images_list_dir):\n",
        "                old_name = os.path.join(self.image_path, listdir[i], images_list_dir[j])\n",
        "                new_name = os.path.join(self.image_path, \"%d-%d.jpg\" % (i, j))\n",
        "\n",
        "                try:\n",
        "                    os.rename(old_name, new_name)\n",
        "                    print(f\"重命名: {old_name} -> {new_name}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"重命名失败: {e}\")\n",
        "\n",
        "                j += 1\n",
        "            i += 1\n",
        "\n",
        "        # 删除空的分类文件夹\n",
        "        for p in range(len(listdir)):\n",
        "            tmp_path = os.path.join(self.image_path, listdir[p])\n",
        "            if os.path.exists(tmp_path) and os.path.isdir(tmp_path):\n",
        "                try:\n",
        "                    os.removedirs(tmp_path)\n",
        "                    print(f\"删除空文件夹: {tmp_path}\")\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "        print(\"图片重命名完成！\")\n",
        "\n",
        "    def resize_img(self, target_size=(200, 200)):\n",
        "        \"\"\"\n",
        "        统一图片尺寸为 200x200\n",
        "        \"\"\"\n",
        "        print(f\"开始调整图片尺寸为 {target_size}...\")\n",
        "        listdir = os.listdir(self.image_path)\n",
        "        success_count = 0\n",
        "        fail_count = 0\n",
        "\n",
        "        for file in listdir:\n",
        "            file_path = os.path.join(self.image_path, file)\n",
        "\n",
        "            if not file.endswith(('.jpg', '.jpeg', '.png')):\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                imread = cv2.imread(file_path)\n",
        "                if imread is None:\n",
        "                    print(f\"无法读取图片: {file_path}\")\n",
        "                    os.remove(file_path)\n",
        "                    fail_count += 1\n",
        "                    continue\n",
        "\n",
        "                resize = cv2.resize(imread, target_size)\n",
        "                cv2.imwrite(file_path, resize)\n",
        "                success_count += 1\n",
        "                print(f\"处理成功: {file} ({success_count}/{len(listdir)})\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"处理失败: {file}, 错误: {e}\")\n",
        "                try:\n",
        "                    os.remove(file_path)\n",
        "                except:\n",
        "                    pass\n",
        "                fail_count += 1\n",
        "\n",
        "        print(f\"图片尺寸调整完成！成功: {success_count}, 失败: {fail_count}\")\n",
        "\n",
        "    def train_data_to_csv(self, csv_name=\"train.csv\"):\n",
        "        \"\"\"\n",
        "        转存图片信息到CSV文件\n",
        "        格式：path, label, label_0, label_1, label_2, label_3, label_4\n",
        "        \"\"\"\n",
        "        print(\"开始生成CSV文件...\")\n",
        "        files = os.listdir(self.image_path)\n",
        "        data = []\n",
        "\n",
        "        for file in files:\n",
        "            if not file.endswith(('.jpg', '.jpeg', '.png')):\n",
        "                continue\n",
        "\n",
        "            # 从文件名提取标签 (格式: 0-1.jpg)\n",
        "            label = file.split('-')[0]\n",
        "            file_path = os.path.join(self.image_path, file)\n",
        "\n",
        "            data.append({\n",
        "                \"path\": file_path,\n",
        "                \"label\": label\n",
        "            })\n",
        "\n",
        "        # 创建DataFrame\n",
        "        frame = pd.DataFrame(data, columns=['path', 'label'])\n",
        "\n",
        "        # One-hot编码\n",
        "        dummies = pd.get_dummies(frame['label'], prefix='label')\n",
        "\n",
        "        # 合并数据\n",
        "        concat = pd.concat([frame, dummies], axis=1)\n",
        "\n",
        "        # 保存为CSV\n",
        "        csv_file = os.path.join(self.csv_path, csv_name)\n",
        "        concat.to_csv(csv_file, index=False)\n",
        "\n",
        "        print(f\"CSV文件已生成: {csv_file}\")\n",
        "        print(f\"总共处理了 {len(data)} 张图片\")\n",
        "        print(\"\\nCSV文件预览:\")\n",
        "        print(concat.head())\n",
        "\n",
        "        return csv_file\n",
        "\n",
        "    def run_all(self):\n",
        "        \"\"\"\n",
        "        执行所有预处理步骤\n",
        "        \"\"\"\n",
        "        print(\"=\" * 60)\n",
        "        print(\"开始数据预处理流程\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # 1. 重命名\n",
        "        self.rename()\n",
        "\n",
        "        # 2. 调整尺寸\n",
        "        self.resize_img()\n",
        "\n",
        "        # 3. 生成CSV\n",
        "        self.train_data_to_csv()\n",
        "\n",
        "        print(\"=\" * 60)\n",
        "        print(\"数据预处理完成！\")\n",
        "        print(\"=\" * 60)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd660925"
      },
      "source": [
        "#### **Usage of Data Preprocessing**\n",
        "\n",
        "To prepare your dataset, you first need to place your images in a directory (e.g., `./picture/` organized by subfolders for each category). Then, instantiate the `DataPreprocess` class and call its `run_all()` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "639390dc"
      },
      "source": [
        "# Example: Initialize and run data preprocessing\n",
        "# Make sure to create a 'picture' directory and populate it with image subfolders like '0', '1', etc.\n",
        "# For example:\n",
        "# ./picture/0/image001.jpg\n",
        "# ./picture/1/image002.jpg\n",
        "\n",
        "# You might need to create dummy image files for this to run without error\n",
        "# if not os.path.exists('./picture/0'):\n",
        "#     os.makedirs('./picture/0')\n",
        "# if not os.path.exists('./picture/1'):\n",
        "#     os.makedirs('./picture/1')\n",
        "# # Example: create a dummy image file\n",
        "# cv2.imwrite('./picture/0/test_image_0.jpg', np.zeros((100,100,3), dtype=np.uint8))\n",
        "# cv2.imwrite('./picture/1/test_image_1.jpg', np.zeros((100,100,3), dtype=np.uint8))\n",
        "\n",
        "# preprocessor = DataPreprocess()\n",
        "# preprocessor.run_all()\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9983c98c"
      },
      "source": [
        "### 2. Model Training Module (`train.py`)\n",
        "\n",
        "This module defines, trains, and saves the CNN model. It includes:\n",
        "\n",
        "-   **Data Loading**: Reads the preprocessed CSV file and splits data into training and testing sets.\n",
        "-   **Batch Generation**: Provides methods to load images and their corresponding one-hot encoded labels in batches during training.\n",
        "-   **CNN Architecture**: Defines a multi-layer CNN with convolutional layers, max-pooling, batch normalization, and fully connected layers.\n",
        "-   **Training Loop**: Manages the training process, including epoch iterations, loss calculation, accuracy evaluation, and model saving."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e685471"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "\n",
        "class CNNModel:\n",
        "    def __init__(self, csv_path=\"./train.csv\", image_path=\"./picture/\"):\n",
        "        self.csv_path = csv_path\n",
        "        self.image_path = image_path\n",
        "        self.batch_size = 16\n",
        "        self.start = 0\n",
        "        self.has_next_batch = True\n",
        "\n",
        "        # GPU配置\n",
        "        self.config = tf.ConfigProto()\n",
        "        self.config.gpu_options.allow_growth = True\n",
        "\n",
        "        # 加载数据\n",
        "        self.load_data()\n",
        "\n",
        "        # 构建模型\n",
        "        self.build_model_graph()\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"\n",
        "        加载CSV数据\n",
        "        \"\"\"\n",
        "        print(\"加载数据集...\")\n",
        "        df = pd.read_csv(self.csv_path)\n",
        "\n",
        "        # 分离训练集和测试集 (80/20)\n",
        "        msk = np.random.rand(len(df)) < 0.8\n",
        "        self.train_data = df[msk]\n",
        "        self.test_data = df[~msk]\n",
        "\n",
        "        self.batches = len(self.train_data) // self.batch_size\n",
        "\n",
        "        print(f\"训练集大小: {len(self.train_data)}\")\n",
        "        print(f\"测试集大小: {len(self.test_data)}\")\n",
        "        print(f\"批次数量: {self.batches}\")\n",
        "\n",
        "    def next_batch(self):\n",
        "        \"\"\"\n",
        "        获取下一批训练数据\n",
        "        \"\"\"\n",
        "        if self.start + self.batch_size > len(self.train_data):\n",
        "            self.has_next_batch = False\n",
        "            return None, None\n",
        "\n",
        "        batch_data = self.train_data[self.start:self.start + self.batch_size]\n",
        "        self.start += self.batch_size\n",
        "\n",
        "        # 读取图片\n",
        "        images = []\n",
        "        labels = []\n",
        "\n",
        "        for _, row in batch_data.iterrows():\n",
        "            img = cv2.imread(row['path'])\n",
        "            img = cv2.resize(img, (200, 200))\n",
        "            img = np.asarray(img, np.float32) / 255.0\n",
        "            images.append(img)\n",
        "\n",
        "            # 获取one-hot标签\n",
        "            label = [row[f'label_{i}'] for i in range(5)]\n",
        "            labels.append(label)\n",
        "\n",
        "        return np.array(images), np.array(labels)\n",
        "\n",
        "    def get_test_data(self):\n",
        "        \"\"\"\n",
        "        获取测试数据\n",
        "        \"\"\"\n",
        "        images = []\n",
        "        labels = []\n",
        "\n",
        "        for _, row in self.test_data.iterrows():\n",
        "            img = cv2.imread(row['path'])\n",
        "            img = cv2.resize(img, (200, 200))\n",
        "            img = np.asarray(img, np.float32) / 255.0\n",
        "            images.append(img)\n",
        "\n",
        "            label = [row[f'label_{i}'] for i in range(5)]\n",
        "            labels.append(label)\n",
        "\n",
        "        return np.array(images), np.array(labels)\n",
        "\n",
        "    def build_model_graph(self):\n",
        "        \"\"\"\n",
        "        构建CNN模型\n",
        "        \"\"\"\n",
        "        print(\"构建CNN模型...\")\n",
        "\n",
        "        with tf.name_scope(\"input\"):\n",
        "            self.x = tf.placeholder(tf.float32, [None, 200, 200, 3], \"x\")\n",
        "            self.y = tf.placeholder(tf.float32, [None, 5], \"y\")\n",
        "\n",
        "        # 卷积层1\n",
        "        with tf.variable_scope(\"conv_layer_1\"):\n",
        "            conv1 = tf.layers.conv2d(self.x, 64, [3, 3], activation=tf.nn.relu, name='conv1')\n",
        "            max1 = tf.layers.max_pooling2d(conv1, [2, 2], [2, 2])\n",
        "            bn1 = tf.layers.batch_normalization(max1, name='bn1')\n",
        "            output1 = tf.layers.dropout(bn1, rate=0.5, name='dropout')\n",
        "\n",
        "        # 卷积层2\n",
        "        with tf.variable_scope(\"conv_layer_2\"):\n",
        "            conv2 = tf.layers.conv2d(output1, 64, [3, 3], activation=tf.nn.relu, name='conv2')\n",
        "            max2 = tf.layers.max_pooling2d(conv2, [2, 2], [2, 2], name='max2')\n",
        "            bn2 = tf.layers.batch_normalization(max2)\n",
        "            output2 = tf.layers.dropout(bn2, rate=0.5, name='dropout')\n",
        "\n",
        "        # 卷积层3\n",
        "        with tf.variable_scope(\"conv_layer_3\"):\n",
        "            conv3 = tf.layers.conv2d(output2, 64, [3, 3], activation=tf.nn.relu, name='conv3')\n",
        "            max3 = tf.layers.max_pooling2d(conv3, [2, 2], [2, 2], name='max3')\n",
        "            bn3 = tf.layers.batch_normalization(max3, name='bn3')\n",
        "            output3 = bn3\n",
        "\n",
        "        # 卷积层4\n",
        "        with tf.variable_scope(\"conv_layer_4\"):\n",
        "            conv4 = tf.layers.conv2d(output3, 32, [3, 3], activation=tf.nn.relu, name='conv4')\n",
        "            max4 = tf.layers.max_pooling2d(conv4, [2, 2], [2, 2], name='max4')\n",
        "            bn4 = tf.layers.batch_normalization(max4, name='bn4')\n",
        "            output = bn4\n",
        "            flatten = tf.layers.flatten(output, 'flatten')\n",
        "\n",
        "        # 全连接层1\n",
        "        with tf.variable_scope(\"fc_layer1\"):\n",
        "            fc1 = tf.layers.dense(flatten, 256, activation=tf.nn.relu)\n",
        "            fc_bn1 = tf.layers.batch_normalization(fc1, name='bn1')\n",
        "            dropout1 = tf.layers.dropout(fc_bn1, rate=0.5)\n",
        "\n",
        "        # 全连接层2\n",
        "        with tf.variable_scope(\"fc_layer2\"):\n",
        "            fc2 = tf.layers.dense(dropout1, 128, activation=tf.nn.relu)\n",
        "            dropout2 = tf.layers.dropout(fc2, rate=0.5)\n",
        "\n",
        "        # 全连接层3\n",
        "        with tf.variable_scope(\"fc_layer3\"):\n",
        "            fc3 = tf.layers.dense(dropout2, 64)\n",
        "            dropout3 = tf.layers.dropout(fc3, rate=0.5)\n",
        "\n",
        "        # 全连接层4\n",
        "        with tf.variable_scope(\"fc_layer4\"):\n",
        "            fc4 = tf.layers.dense(dropout3, 32)\n",
        "\n",
        "        # 全连接层5 (输出层)\n",
        "        with tf.variable_scope(\"fc_layer5\"):\n",
        "            fc5 = tf.layers.dense(fc4, 5)\n",
        "\n",
        "        # 预测和损失\n",
        "        self.softmax = tf.nn.softmax(fc5, name='softmax')\n",
        "        self.predict = tf.argmax(self.softmax, axis=1)\n",
        "        self.loss = tf.reduce_mean(\n",
        "            tf.nn.softmax_cross_entropy_with_logits_v2(logits=fc5, labels=self.y, name='loss')\n",
        "        )\n",
        "\n",
        "        # 准确率\n",
        "        correct_prediction = tf.equal(self.predict, tf.argmax(self.y, axis=1))\n",
        "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "        # 优化器\n",
        "        self.opt = tf.train.AdamOptimizer(learning_rate=0.001).minimize(self.loss)\n",
        "\n",
        "        # TensorBoard\n",
        "        tf.summary.scalar(\"loss\", self.loss)\n",
        "        tf.summary.scalar(\"accuracy\", self.accuracy)\n",
        "        self.merged = tf.summary.merge_all()\n",
        "\n",
        "        print(\"模型构建完成！\")\n",
        "\n",
        "    def train(self, epochs=100, save_interval=5):\n",
        "        \"\"\"\n",
        "        训练模型\n",
        "        \"\"\"\n",
        "        print(\"=\" * 60)\n",
        "        print(\"开始训练模型\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        saver = tf.train.Saver(max_to_keep=3)\n",
        "        sess = tf.InteractiveSession(config=self.config)\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        writer = tf.summary.FileWriter(\"./log\", graph=sess.graph)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            batch_idx = 1\n",
        "            all_loss = 0\n",
        "            all_acc = 0\n",
        "\n",
        "            # 训练一个epoch\n",
        "            while batch_idx <= self.batches and self.has_next_batch:\n",
        "                train_x, train_y = self.next_batch()\n",
        "\n",
        "                _, loss_, accuracy_, merged_ = sess.run(\n",
        "                    [self.opt, self.loss, self.accuracy, self.merged],\n",
        "                    feed_dict={self.x: train_x, self.y: train_y}\n",
        "                )\n",
        "\n",
        "                all_loss += loss_\n",
        "                all_acc += accuracy_\n",
        "\n",
        "                # 进度条\n",
        "                progress = \"=\" * batch_idx + \">\" + \"-\" * (self.batches - batch_idx)\n",
        "                print(f\"\\repoch {epoch+1}/{epochs} -- batch: {batch_idx}/{self.batches} --> \"\n",
        "                      f\"[{progress}] loss: {loss_:.4f}, acc: {accuracy_:.4f}\", end=\"\")\n",
        "\n",
        "                batch_idx += 1\n",
        "                writer.add_summary(merged_, epoch * self.batches + batch_idx - 1)\n",
        "\n",
        "            # Epoch统计\n",
        "            mean_loss = all_loss / self.batches\n",
        "            mean_acc = all_acc / self.batches\n",
        "            print(f\"\\n===epoch {epoch+1}/{epochs}=== > mean loss: {mean_loss:.4f}, mean acc: {mean_acc:.4f}\")\n",
        "\n",
        "            # 测试集评估\n",
        "            test_x, test_y = self.get_test_data()\n",
        "            test_batch_size = min(16, len(test_x))\n",
        "            test_loss_, test_acc_ = sess.run(\n",
        "                [self.loss, self.accuracy],\n",
        "                feed_dict={self.x: test_x[:test_batch_size], self.y: test_y[:test_batch_size]}\n",
        "            )\n",
        "            print(f\"===epoch {epoch+1}/{epochs}=== > test loss: {test_loss_:.4f}, test acc: {test_acc_:.4f}\\n\")\n",
        "\n",
        "            # 重置批次\n",
        "            self.start = 0\n",
        "            self.has_next_batch = True\n",
        "\n",
        "            # 保存模型\n",
        "            if (epoch + 1) % save_interval == 0:\n",
        "                save_path = saver.save(sess, \"./h5_dell/model.ckpt\", global_step=epoch+1)\n",
        "                print(f\"模型已保存: {save_path}\\n\")\n",
        "\n",
        "        print(\"=\" * 60)\n",
        "        print(\"训练完成！\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        sess.close()\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e721213a"
      },
      "source": [
        "#### **Usage of Model Training**\n",
        "\n",
        "After preparing your data and generating `train.csv`, you can train the CNN model. Instantiate the `CNNModel` class and call its `train()` method. You can specify the number of training epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7c50154"
      },
      "source": [
        "# Example: Initialize and train the model\n",
        "# This assumes 'train.csv' has been generated by the DataPreprocess module.\n",
        "\n",
        "# model = CNNModel()\n",
        "# model.train(epochs=10)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a4f0b93"
      },
      "source": [
        "### 3. Image Recognition Module (`predict.py`)\n",
        "\n",
        "This module uses the trained CNN model to classify new images or perform real-time object recognition from a video stream. Key features include:\n",
        "\n",
        "-   **Model Loading**: Restores the trained TensorFlow model from checkpoint files.\n",
        "-   **Image Prediction**: Takes an image path, preprocesses it, and outputs the predicted class and confidence.\n",
        "-   **Video Prediction**: Utilizes a webcam feed for real-time inference, displaying the recognized class and confidence directly on the video frames.\n",
        "-   **Class Labels & Colors**: Defines human-readable class names and corresponding colors for visualization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc6d40ff"
      },
      "source": [
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os # Import os for path manipulation\n",
        "\n",
        "class ImagePredictor:\n",
        "    def __init__(self, model_path=\"./h5_dell/\"):\n",
        "        self.model_path = model_path\n",
        "\n",
        "        # 类别标签\n",
        "        self.class_names = {\n",
        "            0: \"厨余垃圾 (Kitchen Waste)\",\n",
        "            1: \"可回收垃圾 (Recyclable)\",\n",
        "            2: \"有毒垃圾 (Hazardous)\",\n",
        "            3: \"其它垃圾 (Other)\",\n",
        "            4: \"未知类别 (Unknown)\"\n",
        "        }\n",
        "\n",
        "        # 颜色映射 (BGR)\n",
        "        self.colors = {\n",
        "            0: (0, 0, 255),      # 红色\n",
        "            1: (0, 255, 255),    # 黄色\n",
        "            2: (0, 255, 0),      # 绿色\n",
        "            3: (255, 0, 255),    # 紫色\n",
        "            4: (128, 128, 128)   # 灰色\n",
        "        }\n",
        "\n",
        "        # 构建预测图\n",
        "        self.build_predict_graph()\n",
        "\n",
        "    def build_predict_graph(self):\n",
        "        \"\"\"\n",
        "        构建预测用的计算图\n",
        "        \"\"\"\n",
        "        with tf.name_scope(\"input\"):\n",
        "            self.x = tf.placeholder(tf.float32, [None, 200, 200, 3], \"x\")\n",
        "\n",
        "        # 重建网络结构 (与训练时一致)\n",
        "        with tf.variable_scope(\"conv_layer_1\"):\n",
        "            conv1 = tf.layers.conv2d(self.x, 64, [3, 3], activation=tf.nn.relu, name='conv1')\n",
        "            max1 = tf.layers.max_pooling2d(conv1, [2, 2], [2, 2])\n",
        "            bn1 = tf.layers.batch_normalization(max1, name='bn1', training=False)\n",
        "            output1 = bn1\n",
        "\n",
        "        with tf.variable_scope(\"conv_layer_2\"):\n",
        "            conv2 = tf.layers.conv2d(output1, 64, [3, 3], activation=tf.nn.relu, name='conv2')\n",
        "            max2 = tf.layers.max_pooling2d(conv2, [2, 2], [2, 2], name='max2')\n",
        "            bn2 = tf.layers.batch_normalization(max2, training=False)\n",
        "            output2 = bn2\n",
        "\n",
        "        with tf.variable_scope(\"conv_layer_3\"):\n",
        "            conv3 = tf.layers.conv2d(output2, 64, [3, 3], activation=tf.nn.relu, name='conv3')\n",
        "            max3 = tf.layers.max_pooling2d(conv3, [2, 2], [2, 2], name='max3')\n",
        "            bn3 = tf.layers.batch_normalization(max3, name='bn3', training=False)\n",
        "            output3 = bn3\n",
        "\n",
        "        with tf.variable_scope(\"conv_layer_4\"):\n",
        "            conv4 = tf.layers.conv2d(output3, 32, [3, 3], activation=tf.nn.relu, name='conv4')\n",
        "            max4 = tf.layers.max_pooling2d(conv4, [2, 2], [2, 2], name='max4')\n",
        "            bn4 = tf.layers.batch_normalization(max4, name='bn4', training=False)\n",
        "            output = bn4\n",
        "            flatten = tf.layers.flatten(output, 'flatten')\n",
        "\n",
        "        with tf.variable_scope(\"fc_layer1\"):\n",
        "            fc1 = tf.layers.dense(flatten, 256, activation=tf.nn.relu)\n",
        "            fc_bn1 = tf.layers.batch_normalization(fc1, name='bn1', training=False)\n",
        "\n",
        "        with tf.variable_scope(\"fc_layer2\"):\n",
        "            fc2 = tf.layers.dense(fc_bn1, 128, activation=tf.nn.relu)\n",
        "\n",
        "        with tf.variable_scope(\"fc_layer3\"):\n",
        "            fc3 = tf.layers.dense(fc2, 64)\n",
        "\n",
        "        with tf.variable_scope(\"fc_layer4\"):\n",
        "            fc4 = tf.layers.dense(fc3, 32)\n",
        "\n",
        "        with tf.variable_scope(\"fc_layer5\"):\n",
        "            fc5 = tf.layers.dense(fc4, 5)\n",
        "\n",
        "        self.probab = tf.nn.softmax(fc5)\n",
        "        self.predict = tf.argmax(self.probab, axis=1)\n",
        "\n",
        "    def predict_image(self, image_path):\n",
        "        \"\"\"\n",
        "        预测单张图片\n",
        "        \"\"\"\n",
        "        print(f\"加载图片: {image_path}\")\n",
        "\n",
        "        saver = tf.train.Saver()\n",
        "        # Reset the default graph to avoid issues with multiple graph creations\n",
        "        tf.reset_default_graph()\n",
        "        self.build_predict_graph() # Rebuild the graph in the new context\n",
        "        sess = tf.InteractiveSession()\n",
        "\n",
        "        # Restore model\n",
        "        ckpt = tf.train.latest_checkpoint(self.model_path)\n",
        "        if ckpt:\n",
        "            saver.restore(sess, ckpt)\n",
        "            print(f\"模型已加载: {ckpt}\")\n",
        "        else:\n",
        "            print(\"未找到模型文件！\")\n",
        "            sess.close()\n",
        "            return None\n",
        "\n",
        "        # 读取并预处理图片\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            print(\"无法读取图片！\")\n",
        "            sess.close()\n",
        "            return None\n",
        "\n",
        "        image_resized = cv2.resize(image, (200, 200))\n",
        "        image_normalized = np.asarray(image_resized, np.float32) / 255.0\n",
        "        image_batch = np.reshape(\n",
        "            image_normalized,\n",
        "            (1, image_normalized.shape[0], image_normalized.shape[1], image_normalized.shape[2])\n",
        "        )\n",
        "\n",
        "        # 预测\n",
        "        [predict_class, probab] = sess.run(\n",
        "            [self.predict, self.probab],\n",
        "            feed_dict={self.x: image_batch}\n",
        "        )\n",
        "\n",
        "        predict_class = predict_class[0]\n",
        "        confidence = np.max(probab)\n",
        "\n",
        "        # 置信度过低则判定为未知\n",
        "        if confidence < 0.6:\n",
        "            predict_class = 4\n",
        "\n",
        "        print(f\"\\n预测结果:\")\n",
        "        print(f\"  类别: {self.class_names[predict_class]}\")\n",
        "        print(f\"  置信度: {confidence:.2%}\")\n",
        "\n",
        "        # 在图片上显示结果\n",
        "        result_image = image.copy()\n",
        "        color = self.colors[predict_class]\n",
        "        text = f\"{self.class_names[predict_class]} ({confidence:.2%})\"\n",
        "\n",
        "        cv2.putText(\n",
        "            result_image, text, (10, 50),\n",
        "            cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 3, cv2.LINE_AA\n",
        "        )\n",
        "\n",
        "        # Display the image (Note: cv2.imshow does not work directly in Colab notebooks)\n",
        "        # For Colab, you might want to save the image or display it using matplotlib\n",
        "        # cv2.imshow(\"Recognition Result\", result_image)\n",
        "        # cv2.waitKey(0)\n",
        "        # cv2.destroyAllWindows()\n",
        "\n",
        "        # Alternative for Colab: Save image and display\n",
        "        output_image_path = './prediction_result.jpg'\n",
        "        cv2.imwrite(output_image_path, result_image)\n",
        "        print(f\"Prediction result saved to {output_image_path}\")\n",
        "        # To display in Colab, you could use:\n",
        "        # from IPython.display import Image, display\n",
        "        # display(Image(filename=output_image_path))\n",
        "\n",
        "        sess.close()\n",
        "\n",
        "        return predict_class, confidence\n",
        "\n",
        "    def predict_video(self, camera_id=0):\n",
        "        \"\"\"\n",
        "        实时视频识别\n",
        "        \"\"\"\n",
        "        print(f\"启动摄像头 {camera_id}...\")\n",
        "\n",
        "        saver = tf.train.Saver()\n",
        "        tf.reset_default_graph()\n",
        "        self.build_predict_graph()\n",
        "        sess = tf.InteractiveSession()\n",
        "\n",
        "        # 恢复模型\n",
        "        ckpt = tf.train.latest_checkpoint(self.model_path)\n",
        "        if ckpt:\n",
        "            saver.restore(sess, ckpt)\n",
        "            print(f\"模型已加载: {ckpt}\")\n",
        "        else:\n",
        "            print(\"未找到模型文件！\")\n",
        "            sess.close()\n",
        "            return\n",
        "\n",
        "        # 打开摄像头\n",
        "        # NOTE: cv2.VideoCapture(0) for webcam often does not work directly in Colab notebooks\n",
        "        # You might need to use a browser-based webcam solution or upload video files.\n",
        "        capture = cv2.VideoCapture(camera_id)\n",
        "\n",
        "        if not capture.isOpened():\n",
        "            print(\"无法打开摄像头！\")\n",
        "            sess.close()\n",
        "            return\n",
        "\n",
        "        print(\"按 ESC 键退出...\")\n",
        "\n",
        "        while True:\n",
        "            ret, frame = capture.read()\n",
        "\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # 预处理\n",
        "            resize = cv2.resize(frame, (200, 200))\n",
        "            x_ = np.asarray(resize, np.float32) / 255.0\n",
        "            x_ = np.reshape(x_, [1, x_.shape[0], x_.shape[1], x_.shape[2]])\n",
        "\n",
        "            # 预测\n",
        "            [predict_class, probab] = sess.run(\n",
        "                [self.predict, self.probab],\n",
        "                feed_dict={self.x: x_}\n",
        "            )\n",
        "\n",
        "            predict_class = predict_class[0]\n",
        "            confidence = np.max(probab)\n",
        "\n",
        "            # 置信度过低则判定为未知\n",
        "            if confidence < 0.6:\n",
        "                predict_class = 4\n",
        "\n",
        "            # 显示结果\n",
        "            color = self.colors[predict_class]\n",
        "            text = f\"{self.class_names[predict_class]} ({confidence:.2%})\"\n",
        "\n",
        "            cv2.putText(\n",
        "                frame, text, (10, 50),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1.5, color, 3, cv2.LINE_AA\n",
        "            )\n",
        "\n",
        "            # cv2.imshow(\"Real-time Recognition\", frame)\n",
        "\n",
        "            # For Colab, you would need to display frames differently\n",
        "            # For example, convert frame to PIL Image and display or save frames.\n",
        "            # This real-time video display part is challenging in a Colab environment.\n",
        "\n",
        "            # For demonstration purposes, we'll just break after a few frames or on key press\n",
        "            key = cv2.waitKey(1)\n",
        "            if key == 27: # ESC key\n",
        "                break\n",
        "\n",
        "        capture.release()\n",
        "        cv2.destroyAllWindows()\n",
        "        sess.close()\n",
        "\n",
        "        print(\"视频识别结束\")\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f6ad17a"
      },
      "source": [
        "#### **Usage of Image Recognition**\n",
        "\n",
        "To perform predictions, instantiate the `ImagePredictor` class. You can then use `predict_image()` for single images or `predict_video()` for real-time video streams (note that `predict_video` might have limitations in a Colab environment)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92f8fd83"
      },
      "source": [
        "# Example: Predict a single image\n",
        "# You would need a trained model saved in './h5_dell/' and a test image, e.g., './test.jpg'\n",
        "# You can create a dummy test.jpg for testing purposes:\n",
        "# cv2.imwrite('./test.jpg', np.zeros((200,200,3), dtype=np.uint8))\n",
        "\n",
        "# predictor = ImagePredictor()\n",
        "# predictor.predict_image('./test.jpg')\n",
        "\n",
        "# Example: Predict from video (will likely not work directly in Colab without specific setups)\n",
        "# predictor.predict_video()\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5e0f0ad"
      },
      "source": [
        "### 4. Main Program Entry Point (`main.py`)\n",
        "\n",
        "This section defines the `main` function which acts as the entry point for the entire application. It uses `argparse` to allow users to specify the operation mode (preprocess, train, predict_image, predict_video) and other parameters from the command line. This is typical for standalone scripts, but for a Colab notebook, you would typically run the class methods directly as shown in the usage examples above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9600757e"
      },
      "source": [
        "def main():\n",
        "    import argparse\n",
        "\n",
        "    parser = argparse.ArgumentParser(description='CNN Image Classification')\n",
        "    parser.add_argument('--mode', type=str, required=True,\n",
        "                       choices=['preprocess', 'train', 'predict_image', 'predict_video'],\n",
        "                       help='运行模式')\n",
        "    parser.add_argument('--image_path', type=str, default='./test.jpg',\n",
        "                       help='测试图片路径 (predict_image模式使用)')\n",
        "    parser.add_argument('--data_path', type=str, default='./picture/',\n",
        "                       help='数据集路径')\n",
        "    parser.add_argument('--epochs', type=int, default=100,\n",
        "                       help='训练轮数')\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if args.mode == 'preprocess':\n",
        "        # 数据预处理\n",
        "        preprocessor = DataPreprocess(image_path=args.data_path)\n",
        "        preprocessor.run_all()\n",
        "\n",
        "    elif args.mode == 'train':\n",
        "        # 训练模型\n",
        "        model = CNNModel()\n",
        "        model.train(epochs=args.epochs)\n",
        "\n",
        "    elif args.mode == 'predict_image':\n",
        "        # 图片识别\n",
        "        predictor = ImagePredictor()\n",
        "        predictor.predict_image(args.image_path)\n",
        "\n",
        "    elif args.mode == 'predict_video':\n",
        "        # 视频识别\n",
        "        predictor = ImagePredictor()\n",
        "        predictor.predict_video()\n",
        "\n",
        "\n",
        "# The original code's `if __name__ == \"__main__\":` block is intended for script execution.\n",
        "# In a Colab notebook, you would typically call the functions/methods directly\n",
        "# or simulate the argparse behavior if needed.\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     print(\"=\" * 60)\n",
        "#     print(\"CNN 图像分类项目\")\n",
        "#     print(\"=\" * 60)\n",
        "\n",
        "#     # Uncomment the desired section to run\n",
        "\n",
        "#     # 1. 数据预处理\n",
        "#     # preprocessor = DataPreprocess()\n",
        "#     # preprocessor.run_all()\n",
        "\n",
        "#     # 2. 训练模型\n",
        "#     # model = CNNModel()\n",
        "#     # model.train(epochs=100)\n",
        "\n",
        "#     # 3. 图片识别\n",
        "#     # predictor = ImagePredictor()\n",
        "#     # predictor.predict_image('./test.jpg')\n",
        "\n",
        "#     # 4. 视频识别\n",
        "#     # predictor = ImagePredictor()\n",
        "#     # predictor.predict_video()\n",
        "\n",
        "#     main() # This line would execute the argparse logic\n"
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}